## 데이터 변환 

### 데이터 유형 변환 

- as.character() : 문자형 변환
- as.numeric() : 숫자형 변환
- as.double() : 실수형 변환 
- as.logical() : 논리형 (T / F) 변환
- as.integer() : 정수형 변환 

![image](https://user-images.githubusercontent.com/81945553/142623704-aa1b7189-3e7a-49a6-bfb7-5161c39435d3.png)



### 자료구조 변환 

- as.data.frame() : 데이터 -> 데이터프레임 
- as.list() : 데이터 -> 리스트 
- as.matrix() : 데이터 -> 행렬
- as.vector() : 데이터 -> 벡터
- as.factor() : 데이터 -> 요인 

```R
> a <- 0:4
> str(a)
 int [1:5] 0 1 2 3 4
> a <- as.data.frame(a) # 데이터 -> 프레임
> a
  a
1 0
2 1
3 2
4 3
5 4

> a <- 0:9
> a <- as.data.frame(a)
> a <- as.list(a) # 프레임 -> 리스트 
> a
$a
 [1] 0 1 2 3 4 5 6 7 8 9

> a <- 0:4
> a <- as.matrix(a) # 데이터 -> 행렬
> a
     [,1]
[1,]    0
[2,]    1
[3,]    2
[4,]    3
[5,]    4
> str(a)
 int [1:5, 1] 0 1 2 3 4

> a <- 0:9
> a <- as.vector(a)
> a
 [1] 0 1 2 3 4 5 6 7 8 9
> str(a)
 int [1:10] 0 1 2 3 4 5 6 7 8 9
```



### 데이터 범위 변환 

- R의 기본 패키지인 **scale** 함수를 이용하여 정규화와 표준화 수행 

#### 정규화

- 데이터의 범위를 **0과 1 사이로 변환**하여 데이터의 분포를 조정하는 기법 
- 데이터가 가지는 값의 범위를 통일하여 변환하는 것을 의미 



#### Min-Max 정규화

- 데이터를 정규화하는 가장 일반적인 기법 (최솟값 0, 최댓값 1, 나머지 0~1 사이)
- scale 함수에서 center 값을 최댓값, scale 값을 최댓값과 최솟값의 차이로 지정
- 이상값에 너무 많은 영향을 받는다는 단점이 있다.  

```R
> data <- c(1, 3, 5, 7, 9)
> data_minmax <- scale(data, center = 1, scale = 8) # 최솟값 1, 최대-최소 = 8
> data_minmax
     [,1]
[1,] 0.00 # (1-1) / 8 
[2,] 0.25 # (3-1) / 8
[3,] 0.50
[4,] 0.75 # (7-1) / 8
[5,] 1.00
attr(,"scaled:center")
[1] 1
attr(,"scaled:scale")
[1] 8
```

```R
> a <- 1:10 # 사용자 정의 함수를 이용한 MinMax 정규화
> a
 [1]  1  2  3  4  5  6  7  8  9 10
> normalize <- function(a) {
+     return ((a-min(a))/(max(a)-min(a)))
+ }
> normalize(a)
 [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556
 [7] 0.6666667 0.7777778 0.8888889 1.0000000
> as.vector(scale(a)) # zero-centered data로 만들어준다.
 [1] -1.4863011 -1.1560120 -0.8257228 -0.4954337 -0.1651446  0.1651446
 [7]  0.4954337  0.8257228  1.1560120  1.4863011
```

#### 표준화

- 어떤 특성의 값들이 정규분포를 따른다고 가정하고, 값들을 0의 평균, 1의 표준편차를 갖도록 변환해 주는 기법 
- Z-Score : 이상치 문제를 피하는 기법 
  - 데이터의 평균과 표준편차를 구하고, 평균 대비 및 표준편차만큼 데이터가 떨어져 있는지를 점수화한다. 
  - X의 값이 평균과 일치하면 0, 평균보다 작으면 음수, 평균보다 크면 양수가 되며, 표준편차가 크면 Z-스코어는 0에 가까워진다.
  - R의 scale 함수에서 기본값인 center = TRUE, scale = TRUE일 경우 Z-스코어 표준화를 적용할 수 있다. 

```R
> data <- c(1, 3, 5, 7, 9)
> data_zscore <- scale(data) # scale 함수 적용으로 정규화
> mean(data_zscore) # 평균 0 확인
[1] 0
> sd(data_zscore) # 표준편차 1 확인
[1] 1
> data_zscore # z-score 표준화 적용 데이터 확인 
           [,1]
[1,] -1.2649111
[2,] -0.6324555
[3,]  0.0000000
[4,]  0.6324555
[5,]  1.2649111
attr(,"scaled:center")
[1] 5
attr(,"scaled:scale")
[1] 3.162278
```



## 표본 추출 



### 표본 추출법

- 단순 무작위 추출, 계통 추출, 층화 추추르 군집 추출 존재 
- 단순 무작위 추출 : 모집단에서 정해진 규칙 없이 추출 
- 계통 추출 : 모집단을 일정한 간격으로 추출하는 방식
- 층화 추출 : 모집단을 서로 겹치지 않는 계층으로 나누고, 단순 무작위 추출을 수행하는 방식 (내부 동질적, 외부 이질적)
- 군집 추출 : 모집단을 여러 군집으로 나누고 일부 군집의 전체 또는 일부를 추출하는 방식  

### 표본추출 함수

#### sample

- base 패키지의 함수이며, 단순 무작위 추출 수행 

```R
> s <- sample(x=1:10, size=5, replace = FALSE) # 비복원 추출
> s
[1] 2 8 9 4 7
> s <- sample(x=1:10, size=5, replace = TRUE) # 복원 추출
> s
[1] 2 1 7 4 9
> s <- sample(x=1:10, size=5, replace = TRUE, prob = 1:10) # 가중치를 준 표본 추출 
> s
[1] 10  7  7  7 10
```



#### createDataPartition

- caret 패키지의 createDataPartition은 특정 비율로 데이터를 훈련 데이터와 평가 데이터로 랜덤하게 분할하는 함수 
- **층화추출**에 사용

```R
> library(caret)
필요한 패키지를 로딩중입니다: ggplot2
필요한 패키지를 로딩중입니다: lattice
> ds <- createDataPartition(
+     iris$Species, times=1, p=0.7 # 70% 훈련, 30% 평가 데이터로 분할
+ )
> ds
$Resample1
  [1]   1   2   3   5   6  12  13  14  15  16  17  18  19  21  22  23
 [17]  24  25  26  27  29  30  31  33  35  37  38  40  41  42  ...
 [97] 137 138 140 141 142 147 148 149 150
> table(iris[ds$Resample1, "Species"]) # 훈련데이터(70%) 종류별 출력

    setosa versicolor  virginica 
        35         35         35 
> table(iris[-ds$Resample1, "Species"]) # 평가 데이터(30%) 출력

    setosa versicolor  virginica 
        15         15         15 
> idx <- as.vector(ds$Resample1) # 훈련 데이터 셋의 인덱스를 생성
> ds_train <- iris[idx,] 
> ds_test <- iris[-idx,]
```

#### createFolds

- caret 패키지의 createFolds는 k-fold 교차 검증 시 데이터 분할을 위한 함수이다. 
- 훈련 단계에 따라 1개는 평가 데이터, k-1개는 훈련 데이터로 활용한다.

```R
> library(caret)
# list = T (리스트 반환 , F는 행렬), returnTrain (T : 훈련데이터 위치 반환, F : 평가데이터 위치 반환)
> ds_k_fold <- createFolds(iris$Species, k=3, list=TRUE, returnTrain = FALSE)
> ds_k_fold
# x번째 학습시 Foldx를 평가 데이터, 나머지 학습데이터로 적용 
$Fold1
 [1]   1   2   6   7   8   9  13  17  22  23  28  41  43  44  46  50  53
[18]  65  70  71  73  75  76  77  81  82  85  86  88  94  95  98  99 113
[35] 117 120 123 124 125 128 130 131 134 137 139 140 145 148 149

$Fold2
 [1]   3   5  14  15  19  20  21  26  31  33  34  35  36  37  40  45  49
[18]  51  54  55  62  66  67  68  72  74  79  87  89  91  92  96 100 103
[35] 104 105 106 109 111 112 119 121 122 126 129 133 135 136 138 142

$Fold3
 [1]   4  10  11  12  16  18  24  25  27  29  30  32  38  39  42  47  48
[18]  52  56  57  58  59  60  61  63  64  69  78  80  83  84  90  93  97
[35] 101 102 107 108 110 114 115 116 118 127 132 141 143 144 146 147 150
```



## 기초 통계량 추출 

### 중심 경향 통계량

- 데이터의 중심 경향성을 나타내는 기초 통계량에는 평균, 중위수, 최빈수 등이 있다. 

#### 평균(mean)

```R
> x <- c(0:50, 50)
> mean(x, trim = 0.10) # 양쪽 10% 제외한 평균
[1] 25.5
> mean(x, na.rm=TRUE) # 결측값 제외한 평균
[1] 25.48077
> mean(cars$speed)
[1] 15.4
```



#### 중위수 (median)

```R
> x <- c(12, 7, 5, -21, 8, -5)
> x
[1]  12   7   5 -21   8  -5
> median(x)
[1] 6
> median(x, na.rm = TRUE)
[1] 6
```



#### 최빈수 (mode)

- 데이터 값 중에서 빈도수가 가장 높은 데이터 값
- 최빈수를 구하는 함수는 없으므로 직접 **함수 정의** 필요

```R
> getmode <- function(x) {
+     y <- table(x)
+     names(y)[which(y==max(y))]
+ }
> x <- c(2,1,1,3,1)
> getmode(x)
[1] "1"
```



### 산포도 통계량

- 데이터의 흩어진 정도인 산포도를 표현하는 기초 통계량에는 분산, 표준편차, 범위 등이 있다.

### 분산(var)

- 평균으로부터 떨어진 거리 

```R
> v <- c(3,4,2,5,2,4,3,4)
> var(v)
[1] 1.125
> var(1:10)
[1] 9.166667
```



### 표준편차(sd)

- 분산에서 양의 제곱근을 취한 값 

```R
> sd(v)
[1] 1.06066
> sd(1:10)
[1] 3.02765
```



### 범위(diff)

- 최댓값과 최솟값의 차이 

```R
> v <- c(1,7,3,5,11,4,6)
> diff(range(v))
[1] 10
> diff(range(1:10))
[1] 9
```



### 순위 계산

```R
> x
[1] 1 1 5 5 9 7
> row_number(x) # 순서의 중복 없이 순위 표시
[1] 1 2 3 4 6 5
> min_rank(x) # 동일 순위에 대하여 최소 순위
[1] 1 1 3 3 6 5
> dense_rank(x) # 순위의 건너뜀 없이 표시
[1] 1 1 2 2 4 3
> cars %>% 
+     arrange(dist) %>% 
+     mutate(rank=row_number(dist))
   speed dist rank
1      4    2    1
2      7    4    2
3      4   10    3
4      9   10    4
5     12   14    5
6      8   16    6
```



### 예제

- 주어진 데이터 첫 행부터 순서대로 80%까지의 데이터를 학습데이터로 추출 후 변수의 결측 값을 변수의 중앙값으로 대체하고 대체 전의 변수 표준편차 값과의 차이의 절댓값 구하기

```R
dshousing <- read.csv(file = 'housing.csv')
str(dshousing)
summary(dshousing)
head(dshousing)
nrow_end <- nrow(dshousing) * 0.8
ds_train <- dshousing[c(1:nrow_end),]
ds_train
summary(ds_train)
str(ds_train)
median_train <- median(ds_train$total_bedrooms, na.rm=T)
org_sd <- sd(ds_train$total_bedrooms, na.rm=T)
ds_train$total_bedrooms[is.na(ds_train$total_bedrooms)] <- median_train
trans_sd <- sd(ds_train$total_bedrooms)

diff_sd <- abs(trans_sd - org_sd)
print(diff_sd)
```



## 상관 분석

- 두 변수 사이에 존재하는 상호 연관성의 존재 여부와 강도를 측정하여 분석하는 기법
- 산점도, 공분산을 통해 표현
- 공분산 : 2개의 변수 사이의 상관 정도를 나타내는 값 
- cor 함수를 통하여 계산할 수 있다. 
  - method (pearson(기본), kendall(켄달 순위 상관 계수), spearman(스피어만 순위 상관 계수))
  - -1 ~ 1 사이의 값을 가지며 1에 가까울 수록 강한 상관관계를 갖는다. 
- cor.test를 통해 가설검정 가능 

```R
library(mlbench)
data(PimaIndiansDiabetes)
df_pima <- PimaIndiansDiabetes[c(3:5,8)]
str(df_pima)
summary(df_pima)
cor(x=df_pima, method="pearson")
cor(x=df_pima, method="spearman")
cor(x=df_pima, method="kendall")
```

```R
> shapiro.test(df_pima$triceps)

	Shapiro-Wilk normality test

data:  df_pima$triceps
W = 0.90463, p-value < 2.2e-16
# p-value가 0.05보다 작으므로 귀무가설(정규분포를 따른다) 기각 -> 비모수검정 필요 (cor.test)

> cor.test(df_pima$triceps, df_pima$insulin, method="kendall")

	Kendall's rank correlation tau

data:  df_pima$triceps and df_pima$insulin
z = 15.535, p-value < 2.2e-16
alternative hypothesis: true tau is not equal to 0
sample estimates:
      tau 
0.4200664 
# 귀무가설을 기각하고, 양의 선형관계임을 알 수 있다.
```



## 변수 선택

- 성능 향상을 위해 알고리즘과 선택기준을 통해 변수 선택을 한다. 
- step() : AIC가 작아지는 방향으로 단계적 변수 선택
  - direction : 전진 선택법(forward), 후진 소거법(backward), 단계적 방법(both) 

```R
data(mtcars)
m1 <- lm(hp~., data=mtcars)
m2 <- step(m1, direction="both")
> formula(m2)
hp ~ disp + wt + carb
# hp 종속변수에 따른 독립변수 선택은 disp ~... 이다.
```

